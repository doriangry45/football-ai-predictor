# AI Studio Entegrasyon Rehberi

Bu rehber, Google AI Studio'da geliÅŸtirilen prompt'larÄ± `football-ai-predictor` projesine nasÄ±l entegre edeceÄŸini anlatÄ±r.

---

## HÄ±zlÄ± BaÅŸlangÄ±Ã§ (5 dakika)

### 1. Google AI Studio'da Prompt Test Et

```
1. https://aistudio.google.com aÃ§mÄ±ÅŸ
2. "+ Create" â†’ "New chat"
3. Åžu prompt'Ä± kopyala ve test et:
```

**Test Prompt:**
```
Futbol analisti olarak, aÅŸaÄŸÄ±daki maÃ§larÄ± Over 2.5 tahmini yap.

MaÃ§lar:
[
  {
    "home": "Arsenal",
    "away": "Chelsea",
    "league": "Premier League"
  }
]

YanÄ±t format:
{
  "matches": [
    {
      "home": "Arsenal",
      "away": "Chelsea",
      "prediction": "OVER",
      "probability": 75,
      "reasoning": "Her iki takÄ±mÄ±n saldÄ±rgan oyunu",
      "tweet": "Tahmin: Over 2.5 ðŸ”¥"
    }
  ]
}

YanÄ±t SADECE JSON.
```

**Send** bas â†’ JSON al

---

### 2. app.py'de Prompt'Ä± GÃ¼ncelle

Dosya: `services/feature-002-ai-predictor/app.py`

**Åžu kÄ±smÄ± bul** (satÄ±r ~180 civarÄ±nda):

```python
def ai_predict(fixtures_data, query="over 2.5"):
    """Analyze fixtures with Gemini."""
    fixtures = fixtures_data.get("response", [])[:10]
    
    if not fixtures:
        return {"matches": [], "error": "No fixtures available"}
    
    fixture_summary = []
    for f in fixtures:
        try:
            h = f.get("teams", {}).get("home", {})
            a = f.get("teams", {}).get("away", {})
            fixture_summary.append({
                "id": f.get("fixture", {}).get("id"),
                "home": h.get("name", "Unknown"),
                "away": a.get("name", "Unknown"),
                "date": f.get("fixture", {}).get("date", ""),
                "status": f.get("fixture", {}).get("status", {}).get("short", "")
            })
        except Exception as e:
            logging.warning(f"Parse fixture error: {e}")
    
    prompt = f"""
    Analyze these upcoming football fixtures for "{query}" predictions:
    {json.dumps(fixture_summary, indent=2)}
    
    For each fixture, provide:
    1. Over 2.5 probability (0-100)
    2. Key analysis reasoning
    3. A short tweet (Turkish)
    
    Return as JSON: {{"matches": [{{"home": "", "away": "", "prediction": "OVER/UNDER", "probability": 0, "reasoning": "", "tweet": ""}}]}}
    """
```

**YENÄ° PROMPT (AI Studio'dan test edilmiÅŸ) ile deÄŸiÅŸtir:**

```python
def ai_predict(fixtures_data, query="over 2.5"):
    """Analyze fixtures with Gemini."""
    fixtures = fixtures_data.get("response", [])[:10]
    
    if not fixtures:
        return {"matches": [], "error": "No fixtures available"}
    
    fixture_summary = []
    for f in fixtures:
        try:
            h = f.get("teams", {}).get("home", {})
            a = f.get("teams", {}).get("away", {})
            fixture_summary.append({
                "id": f.get("fixture", {}).get("id"),
                "home": h.get("name", "Unknown"),
                "away": a.get("name", "Unknown"),
                "date": f.get("fixture", {}).get("date", ""),
                "status": f.get("fixture", {}).get("status", {}).get("short", "")
            })
        except Exception as e:
            logging.warning(f"Parse fixture error: {e}")
    
    # UPDATED PROMPT (v2 - AI Studio tested)
    prompt = f"""
    Futbol analisti olarak, aÅŸaÄŸÄ±daki maÃ§larÄ± "{query}" tahmini yap.

    MAÃ‡LAR:
    {json.dumps(fixture_summary, indent=2)}

    YANIT FORMATI (JSON SADECE):
    {{
      "matches": [
        {{
          "home": "TakÄ±m1",
          "away": "TakÄ±m2",
          "prediction": "OVER veya UNDER",
          "probability": 0-100 arasÄ± sayÄ±,
          "reasoning": "2-3 cÃ¼mle kÄ±sa analiz",
          "tweet": "Maksimum 140 karakterlik TÃ¼rkÃ§e tweet"
        }}
      ]
    }}

    Analiz faktÃ¶rleri:
    1. Her iki takÄ±mÄ±n ortalama gol sayÄ±sÄ±
    2. Defans gÃ¼cÃ¼
    3. Ev sahibi/deplasman avantajÄ±
    4. Son form
    
    YanÄ±t SADECE geÃ§erli JSON olmalÄ±.
    """
```

### 3. Test Et

```powershell
# Terminal'de
pytest tests/test_predictor.py::test_api_predict -v

# Ya da local Ã§alÄ±ÅŸtÄ±r
python services/feature-002-ai-predictor/app.py
# http://localhost:5000 aÃ§Ä±p "Tahminleri Getir" basÄ±lÄ±
```

---

## DetaylÄ± Kurulum (Production)

### AdÄ±m 1: Google AI Studio HesabÄ± Kur

```
1. https://aistudio.google.com git
2. Sign in (Google hesabÄ± gerekli)
3. Dashboard > "+ Create" > "New chat"
```

### AdÄ±m 2: Prompt'larÄ± Versiyonla

`prompts/ai_studio_prompts.md` dosyasÄ±nda mevcut prompt'lar:
- **Prompt 1**: Over/Under 2.5 (en temel)
- **Prompt 2**: BTTS (Both Teams to Score)
- **Prompt 3**: Result (1X2)
- **Prompt 4**: Advanced (istatistik)
- **Prompt 5**: Form Analysis

**Hangi prompt kullanacaÄŸÄ±nÄ± seÃ§:**

```python
# app.py'de conditional olarak kullan
if query == "over 2.5":
    prompt = get_prompt_over_under_25()  # Prompt 1
elif query == "btts":
    prompt = get_prompt_btts()  # Prompt 2
elif query == "result":
    prompt = get_prompt_result()  # Prompt 3
```

### AdÄ±m 3: API Key & Authentication

```python
# app.py'de zaten setup var
import google.generativeai as genai
genai.configure(api_key=os.getenv("GOOGLE_AI_API_KEY", ""))
model = genai.GenerativeModel('gemini-2.5-pro')
```

**Gerekli**: `GOOGLE_AI_API_KEY` environment variable set edilmeli.

```powershell
# .env dosyasÄ±nda
GOOGLE_AI_API_KEY=your_api_key_here
```

### AdÄ±m 4: Error Handling

AI Studio prompt'unuzun fail olmasÄ± durumunda fallback mekanizmasÄ±:

```python
# app.py'de zaten var (satÄ±r ~250)
try:
    response = model.generate_content(prompt)
    text = response.text
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        json_str = text[start:end]
        return json.loads(json_str)
except json.JSONDecodeError:
    pass

# Fallback: dummy response
return {
    "matches": [
        {
            "home": f["home"],
            "away": f["away"],
            "prediction": "ANALYZING",
            "probability": 50,
            "reasoning": "Analiz devam ediyor",
            "tweet": "Tahmin yÃ¼kleniyor..."
        }
        for f in fixture_summary
    ]
}
```

---

## Prompt GeliÅŸtirme Workflow

### Iteratif Ä°yileÅŸtirme

**DÃ¶ngÃ¼:**
1. Google AI Studio'da prompt'u test et
2. Ã‡Ä±ktÄ±yÄ± deÄŸerlendir (format, doÄŸruluk, diÄŸer)
3. Prompt'u optimize et
4. app.py'de gÃ¼ncelle
5. Local test et
6. Versel'e push ve prod test et

### Ã–rnek GeliÅŸtirme

**v1.0 (Temel):**
```
Predict over/under 2.5 for these matches:
[data]

Return JSON.
```

**Ã‡Ä±ktÄ±:** {"matches": [...]}
**Problem:** Reasoning Ã§ok kÄ±sa, probability biraz random

**v1.1 (Ä°yileÅŸtirilmiÅŸ):**
```
Futbol analisti: Over/Under 2.5 tahmini yap.

MaÃ§lar: [data]

Analiz yap:
1. Her takÄ±mÄ±n ortalama gol sayÄ±sÄ±
2. Son form (last 5 matches)
3. Defans gÃ¼cÃ¼

YanÄ±t JSON format:
{
  "matches": [
    {
      "home": "...",
      "away": "...",
      "prediction": "OVER|UNDER",
      "probability": 70,
      "reasoning": "3-5 cÃ¼mle detaylÄ± analiz",
      "tweet": "140 char TÃ¼rkÃ§e"
    }
  ]
}
```

**Ã‡Ä±ktÄ±:** Daha detaylÄ± reasoning, yÃ¼ksek probability
**Result:** âœ… Kuruldu

---

## Sorun Giderme

### Problem: "JSON Parse Error"

```
Gemini'nin Ã§Ä±ktÄ±sÄ± JSON parse edilemiyor.
```

**Ã‡Ã¶zÃ¼m:**
1. Prompt'a ekle: "YanÄ±t SADECE geÃ§erli JSON olmalÄ±"
2. Ã–rnek JSON ver (few-shot prompting)
3. AI Studio'da test et, Ã§Ä±ktÄ±yÄ± doÄŸrula

### Problem: "Reasoning Ã§ok kÄ±sa"

```
Prediction ama "Iyi maÃ§" gibi 1 cÃ¼mle.
```

**Ã‡Ã¶zÃ¼m:**
- Prompt'a ekle: "Reasoning: 3-5 cÃ¼mle detaylÄ± analiz"
- Ã–rnek ver
- Token limit'ini kontrol et (fazla limitli prompt)

### Problem: "Gemini API Error"

```
rate limit exceeded / quota
```

**Ã‡Ã¶zÃ¼m:**
1. Quota check et: https://console.cloud.google.com/apis/dashboard
2. Rate limit'i artÄ±r
3. Caching ekle (Redis, Supabase)

### Problem: "TÃ¼rkÃ§e tweet karakterler yanlÄ±ÅŸ"

```
"Ã§ÄŸÄ±ÅŸÃ¼Ã¶Ã§" karakterleri kÄ±rÄ±lÄ±yor.
```

**Ã‡Ã¶zÃ¼m:**
```python
# app.py'de
tweet = response.get("tweet", "")
tweet = tweet.encode('utf-8').decode('utf-8')  # normalize
```

---

## Advanced: Prompt Chaining

Birden fazla prompt zincirleme:

```python
def ai_predict_advanced(fixtures_data):
    """Multi-step prediction."""
    
    # Step 1: Fetch team stats (RapidAPI)
    stats = fetcher.fetch_team_stats(...)
    
    # Step 2: Gemini - Form analysis
    form_analysis = model.generate_content(
        prompt_team_form(stats)
    )
    
    # Step 3: Gemini - Over/Under prediction
    prediction = model.generate_content(
        prompt_over_under(fixtures_data, form_analysis)
    )
    
    # Step 4: Gemini - Generate tweet
    tweet = model.generate_content(
        prompt_tweet(prediction)
    )
    
    return {
        "form": form_analysis,
        "prediction": prediction,
        "tweet": tweet
    }
```

---

## Monitoring & Analytics

### Prediction Accuracy Tracking

```python
# Supabase'e kaydet
def log_prediction(match_id, prediction, actual_result):
    supabase.table('predictions').insert({
        "match_id": match_id,
        "predicted": prediction,
        "actual": actual_result,
        "correct": prediction == actual_result,
        "timestamp": datetime.now()
    }).execute()

# Dashboard
SELECT 
    COUNT(*) as total_predictions,
    SUM(CASE WHEN correct THEN 1 ELSE 0 END) / COUNT(*) as accuracy
FROM predictions
WHERE created_at > NOW() - INTERVAL '7 days'
```

### Prompt Performance

```python
# Hangi prompt'un daha iyi performans gÃ¶sterdiÄŸini analiz et
SELECT 
    prompt_version,
    AVG(accuracy) as avg_accuracy,
    COUNT(*) as usage_count
FROM predictions
GROUP BY prompt_version
```

---

## YapÄ±lacaklar (TODO)

- [ ] Multi-language prompt'lar (Ä°ngilizce, Ä°spanyolca)
- [ ] Real-time pitch data entegrasyonu
- [ ] Injury/suspension data ekleme
- [ ] Head-to-head history analizi
- [ ] Weather factor ekleme
- [ ] Prompt A/B testing dashboard
- [ ] Automatic prompt optimization (feedback loop)

---

**Son GÃ¼ncelleme:** 13 Nov 2025
**BakÄ±m Eden:** AI Predictions Team
**Versiyon:** 2.0
